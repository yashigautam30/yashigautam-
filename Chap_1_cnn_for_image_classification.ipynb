{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashigautam30/yashigautam-/blob/main/Chap_1_cnn_for_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NcIIc_P1xro"
      },
      "source": [
        "## STEP 1: SELECT RIGHT VERSION OF TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE2zTcHEJUGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2ff0f3-b348-4421-e844-293a7de52c46"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78RhkOKM3Ld8"
      },
      "source": [
        "## STEP 2: CLONE GITHUB PROJECT (FOR EASY ACCESS TO DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QCWniNOVt-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f05273d-cf5a-4dc4-a30b-c4af22c5534e"
      },
      "source": [
        "!git clone https://github.com/mesushan/CNN-for-image-Classification.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CNN-for-image-Classification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un6b6Tdxeccs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58f9271-7ef8-444d-ec06-e2c42d876762"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN-for-image-Classification  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S_E5AgNJkNA"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6MNMEzKBxs"
      },
      "source": [
        "# Initialising the CNN\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RWO-fud3jLD"
      },
      "source": [
        "## Step 3: ADDING CONVOLUTION LAYER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1p3ZYBEKnQD"
      },
      "source": [
        "# 32 feature detectors with 3*3 dimensions so the convolution layer compose of 32 feature maps\n",
        "# 128 by 128 dimensions with colored image(3 channels)  (tensorflow backend)\n",
        "input_size = (128, 128)\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, 3, input_shape = (*input_size, 3), activation = 'relu'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGnBAso3zyT"
      },
      "source": [
        "## STEP 4: ADDING POOLING LAYER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEiPkwwULNeC"
      },
      "source": [
        "# reduce the size of feature maps and therefore reduce the number of nodes in the future fully connected layer (reduce time complexity, less compute intense without losing the performace). 2 by 2 deminsion is the recommended option\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9HXpcCV4xFU"
      },
      "source": [
        "## STEP 5: ADDING SECOND CONVOLUTION LAYER WITH POOLIING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoh6opl-MPpA"
      },
      "source": [
        "model.add(tf.keras.layers.Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvp8NS-85iWn"
      },
      "source": [
        "## STEP 6: ADDING FLATTENING LAYER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryYAi7KIMd6n"
      },
      "source": [
        "# flatten all the feature maps in the pooling layer into single vector\n",
        "model.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE8mbDLq54_p"
      },
      "source": [
        "## STEP 7: ADDING A FULLY CONNECTED LAYER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIo_G3EeMlAo"
      },
      "source": [
        "# making classic ann which compose of fully connected layers\n",
        "# number of nodes in hidden layer (output_dim) (common practice is to take the power of 2)\n",
        "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbrjo20M6CXH"
      },
      "source": [
        "## STEP 8: COMPILING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jwlI36vMvJW"
      },
      "source": [
        "# Compiling the CNN\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CWYiHqn6SiJ"
      },
      "source": [
        "## STEP 9: FITTING THE CNN TO THE IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggxWEo0-M1h3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca14cd94-a8fa-4f85-eee3-94795d9c6fd5"
      },
      "source": [
        "# image augmentation technique to enrich our dataset(training set) without adding more images so get good performance  results with little or no overfitting even with the small amount of images\n",
        "# used from keras documentation (flow_from_directory method)\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batch_size = 32\n",
        "# image augmentation part\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# create training set\n",
        "# wanna get higher accuracy -> inccrease target_size\n",
        "training_set = train_datagen.flow_from_directory('/content/CNN-for-image-Classification/dataset/training_set',\n",
        "                                                 target_size = input_size,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "# create test set\n",
        "# wanna get higher accuracy -> inccrease target_size\n",
        "test_set = test_datagen.flow_from_directory('/content/CNN-for-image-Classification/dataset/test_set',\n",
        "                                            target_size = input_size,\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "# fit the cnn model to the trainig set and testing it on the test set\n",
        "model.fit(training_set,\n",
        "          steps_per_epoch = 8000/batch_size,\n",
        "          epochs = 3,\n",
        "          validation_data = test_set,\n",
        "          validation_steps = 2000/batch_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 48s 177ms/step - loss: 0.6872 - accuracy: 0.5452 - val_loss: 0.6704 - val_accuracy: 0.5610\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 42s 167ms/step - loss: 0.6617 - accuracy: 0.6105 - val_loss: 0.6345 - val_accuracy: 0.6490\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 42s 169ms/step - loss: 0.6350 - accuracy: 0.6355 - val_loss: 0.6103 - val_accuracy: 0.6720\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d39106d59f0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FablVLKI1ujz"
      },
      "source": [
        "## STEP 10: MAKING NEW *PREDICTIONS*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkpQ9_Bbdgug"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OARxcBiKqhaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e6bc9e-9924-478d-cc11-3bb282eb6afe"
      },
      "source": [
        "test_image = image.load_img('/content/CNN-for-image-Classification/dataset/single_prediction/cat_or_dog_4.jpg', target_size= input_size)\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 155ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yephYECUq3BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081457e1-4a18-4f97-9a43-aaf6649ca6b9"
      },
      "source": [
        "training_set.class_indices"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cats': 0, 'dogs': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwfR3qnDr2D2"
      },
      "source": [
        "if result [0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-LuaKWdsKIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35e8930f-911b-4179-a63c-b7879ea83a5f"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dog'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNTVV8xoVuMN"
      },
      "source": [
        "### correct prediction made :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpVRkKU1Mo1d"
      },
      "source": [
        "#### The model shows the accuracy of 79.34 percent for the training set and 79.55 for the validation set. Can be improved with further parameter tuning if needed. ex. increasing the epochs, adding more convolution layer, changing input size of image, etc."
      ]
    }
  ]
}